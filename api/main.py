"""
Video Service - FastAPI Application

Production-ready REST API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Celery + Redis –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.

–ó–∞–ø—É—Å–∫:
    uvicorn api.main:app --reload

–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:
    http://localhost:8000/docs
"""
from __future__ import annotations

import json
import os
import shutil
import uuid
from datetime import datetime
from pathlib import Path
import asyncio
from typing import Any, Dict, List, Optional

from fastapi import BackgroundTasks, FastAPI, File, HTTPException, UploadFile, Query, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel, Field

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
TEMP_DIR = Path(os.environ.get("VIDEO_SERVICE_TEMP_DIR", "temp"))
RESULTS_DIR = Path(os.environ.get("VIDEO_SERVICE_OUTPUT_DIR", "results"))
USE_CELERY = os.environ.get("USE_CELERY", "false").lower() == "true"
ALLOWED_INPUT_DIR_RAW = str(os.environ.get("VIDEO_SERVICE_ALLOWED_INPUT_DIR", "") or "").strip()
ALLOWED_INPUT_DIR = Path(ALLOWED_INPUT_DIR_RAW).resolve() if ALLOWED_INPUT_DIR_RAW else None

TEMP_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)


def _is_allowed_input_path(path: Path) -> bool:
    if ALLOWED_INPUT_DIR is None:
        return False
    try:
        return path.resolve().is_relative_to(ALLOWED_INPUT_DIR)
    except Exception:
        return False


def _cleanup_input_if_temp(video_path: str) -> None:
    try:
        p = Path(video_path).resolve()
        temp_root = TEMP_DIR.resolve()
        if temp_root in p.parents:
            p.unlink()
    except Exception:
        return


# ============================================================================
# Pydantic Models
# ============================================================================

class AnalysisRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ."""
    max_clips: int = Field(8, ge=1, le=20, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–ø–æ–≤")
    min_duration: float = Field(30.0, ge=10, le=300, description="–ú–∏–Ω. –¥–ª–∏–Ω–∞ –∫–ª–∏–ø–∞ (—Å–µ–∫)")
    max_duration: float = Field(60.0, ge=15, le=600, description="–ú–∞–∫—Å. –¥–ª–∏–Ω–∞ –∫–ª–∏–ø–∞ (—Å–µ–∫)")
    enable_llm: bool = Field(False, description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM refinement")


class TaskStatus(BaseModel):
    """–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞."""
    task_id: str
    status: str  # pending, processing, completed, failed
    progress: float = 0.0
    created_at: Optional[str] = None
    completed_at: Optional[str] = None
    result_url: Optional[str] = None
    error: Optional[str] = None


class ViralClipResponse(BaseModel):
    """Viral –∫–ª–∏–ø."""
    id: str = ""
    start: float
    end: float
    duration: float = 0.0
    score: float
    score_breakdown: Dict[str, float] = {}
    anchor_type: str = ""
    reasons: List[str] = []


class ChapterResponse(BaseModel):
    """–ì–ª–∞–≤–∞."""
    id: str = ""
    start: float
    end: float
    duration: float = 0.0
    title: str
    description: str = ""


class AnalysisSummaryResponse(BaseModel):
    """–°–≤–æ–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞."""
    total_scenes: int = 0
    total_speech_duration: float = 0.0
    speech_ratio: float = 0.0
    mean_motion: float = 0.0
    mean_loudness: float = 0.0
    mean_interest: float = 0.0
    detected_language: Optional[str] = None


class AnalysisResultResponse(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞."""
    task_id: str
    video_name: str
    duration_seconds: float
    processing_time_seconds: float
    viral_clips: List[ViralClipResponse]
    chapters: List[ChapterResponse] = []
    summary: AnalysisSummaryResponse = AnalysisSummaryResponse()
    created_at: Optional[str] = None


class HealthResponse(BaseModel):
    """Health check response."""
    status: str
    version: str
    timestamp: str
    gpu_available: bool
    celery_enabled: bool


class AnalyzePathRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞, –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –Ω–∞ –¥–∏—Å–∫–µ —Å–µ—Ä–≤–µ—Ä–∞ (–±–µ–∑ upload)."""
    path: str = Field(..., min_length=1, description="–ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞/—Å–µ—Ä–≤–µ—Ä–∞")


# ============================================================================
# FastAPI App
# ============================================================================

app = FastAPI(
    title="Video Analyzer API",
    description="REST API –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ viral-–º–æ–º–µ–Ω—Ç–æ–≤ –≤ –≤–∏–¥–µ–æ",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í production –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# Task Status via Redis
# ============================================================================

def get_redis_client():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç Redis –∫–ª–∏–µ–Ω—Ç."""
    try:
        import redis
        redis_url = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
        return redis.from_url(redis_url)
    except ImportError:
        return None


def save_task_meta(task_id: str, meta: Dict[str, Any]) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –≤ Redis."""
    client = get_redis_client()
    if client:
        key = f"task_meta:{task_id}"
        client.setex(key, 86400, json.dumps(meta))  # TTL 24h


def get_task_meta(task_id: str) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Redis."""
    client = get_redis_client()
    if client:
        key = f"task_meta:{task_id}"
        data = client.get(key)
        if data:
            return json.loads(data)
    return None


def _publish_task_event(task_id: str, payload: Dict[str, Any]) -> None:
    """–ü—É–±–ª–∏–∫—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∑–∞–¥–∞—á–∏ –≤ Redis pubsub (–¥–ª—è WebSocket)."""
    client = get_redis_client()
    if not client:
        return
    try:
        channel = f"task_events:{task_id}"
        client.publish(channel, json.dumps(payload, ensure_ascii=False))
    except Exception:
        # pubsub –Ω–µ –¥–æ–ª–∂–µ–Ω –ª–æ–º–∞—Ç—å –ø–∞–π–ø–ª–∞–π–Ω
        return


def update_task_progress(
    task_id: str,
    progress: float,
    status: str = "processing",
    message: Optional[str] = None,
) -> None:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –∑–∞–¥–∞—á–∏ + –ø—É–±–ª–∏–∫—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ –¥–ª—è WebSocket."""
    meta = get_task_meta(task_id) or {}
    meta["progress"] = progress
    meta["status"] = status
    if message:
        meta["message"] = message
    save_task_meta(task_id, meta)
    _publish_task_event(
        task_id,
        {
            "task_id": task_id,
            "status": status,
            "progress": progress,
            "message": message,
        },
    )


@app.websocket("/ws/tasks/{task_id}")
async def ws_task_progress(websocket: WebSocket, task_id: str) -> None:
    """WebSocket –∫–∞–Ω–∞–ª –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∑–∞–¥–∞—á–∏ (–±–µ–∑ polling —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã UI)."""
    await websocket.accept()

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Å–Ω—ç–ø—à–æ—Ç
    meta = get_task_meta(task_id)
    if meta:
        await websocket.send_text(
            json.dumps(
                {
                    "task_id": task_id,
                    "status": meta.get("status", "unknown"),
                    "progress": meta.get("progress", 0.0),
                    "message": meta.get("message"),
                    "error": meta.get("error"),
                },
                ensure_ascii=False,
            )
        )

    redis_url = os.environ.get("REDIS_URL", "redis://localhost:6379/0")
    try:
        import redis.asyncio as redis  # type: ignore
    except Exception:
        redis = None  # type: ignore

    if not redis:
        # Fallback: —Å–µ—Ä–≤–µ—Ä–Ω—ã–π polling Redis (UI –Ω–µ –¥–µ–ª–∞–µ—Ç HTTP polling)
        try:
            while True:
                await asyncio.sleep(1.0)
                meta = get_task_meta(task_id) or {}
                await websocket.send_text(
                    json.dumps(
                        {
                            "task_id": task_id,
                            "status": meta.get("status", "unknown"),
                            "progress": meta.get("progress", 0.0),
                            "message": meta.get("message"),
                            "error": meta.get("error"),
                        },
                        ensure_ascii=False,
                    )
                )
        except WebSocketDisconnect:
            return

    client = redis.from_url(redis_url, decode_responses=True)
    pubsub = client.pubsub()
    channel = f"task_events:{task_id}"

    try:
        await pubsub.subscribe(channel)

        while True:
            try:
                msg = await pubsub.get_message(ignore_subscribe_messages=True, timeout=1.0)
                if msg and msg.get("data"):
                    await websocket.send_text(str(msg["data"]))
                else:
                    await asyncio.sleep(0.1)
            except WebSocketDisconnect:
                break
    finally:
        try:
            await pubsub.unsubscribe(channel)
            await pubsub.close()
        except Exception:
            pass
        try:
            await client.close()
        except Exception:
            pass


# ============================================================================
# Endpoints
# ============================================================================

@app.get("/health", response_model=HealthResponse, tags=["System"])
async def health_check():
    """Health check endpoint."""
    try:
        import torch
        gpu_available = torch.cuda.is_available()
    except ImportError:
        gpu_available = False

    return HealthResponse(
        status="healthy",
        version="2.0.0",
        timestamp=datetime.utcnow().isoformat(),
        gpu_available=gpu_available,
        celery_enabled=USE_CELERY,
    )


@app.post("/analyze", response_model=TaskStatus, tags=["Analysis"])
async def create_analysis(
    background_tasks: BackgroundTasks,
    video: UploadFile = File(...),
    max_clips: int = Query(8, ge=1, le=20),
    min_duration: float = Query(30.0, ge=10, le=300),
    max_duration: float = Query(60.0, ge=15, le=600),
    enable_llm: bool = Query(False),
):
    """
    –°–æ–∑–¥–∞—ë—Ç –∑–∞–¥–∞—á—É –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç task_id –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.
    –ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (Celery –∏–ª–∏ BackgroundTasks).
    """
    if not video.filename:
        raise HTTPException(400, "Filename is required")

    allowed_extensions = {".mp4", ".mkv", ".avi", ".mov", ".webm"}
    ext = Path(video.filename).suffix.lower()
    if ext not in allowed_extensions:
        raise HTTPException(400, f"Unsupported format. Allowed: {allowed_extensions}")

    task_id = str(uuid.uuid4())
    video_path = TEMP_DIR / f"{task_id}{ext}"

    try:
        with open(video_path, "wb") as f:
            shutil.copyfileobj(video.file, f)
    except Exception as e:
        raise HTTPException(500, f"Failed to save video: {e}")

    settings = {
        "max_clips": max_clips,
        "min_duration": min_duration,
        "max_duration": max_duration,
        "enable_llm": enable_llm,
    }

    created_at = datetime.utcnow().isoformat()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
    task_meta = {
        "task_id": task_id,
        "status": "pending",
        "progress": 0.0,
        "created_at": created_at,
        "video_path": str(video_path),
        "video_name": video.filename,
        "settings": settings,
    }
    save_task_meta(task_id, task_meta)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
    if USE_CELERY:
        from api.celery_app import analyze_video
        analyze_video.delay(str(video_path), settings, task_id)
    else:
        background_tasks.add_task(run_analysis_task, task_id, str(video_path), settings)

    return TaskStatus(
        task_id=task_id,
        status="pending",
        progress=0.0,
        created_at=created_at,
    )


@app.post("/analyze-path", response_model=TaskStatus, tags=["Analysis"])
async def create_analysis_by_path(
    background_tasks: BackgroundTasks,
    request: AnalyzePathRequest,
    max_clips: int = Query(8, ge=1, le=20),
    min_duration: float = Query(30.0, ge=10, le=300),
    max_duration: float = Query(60.0, ge=15, le=600),
    enable_llm: bool = Query(False),
):
    """
    –°–æ–∑–¥–∞—ë—Ç –∑–∞–¥–∞—á—É –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ –ø–æ –ø—É—Ç–∏ –Ω–∞ –¥–∏—Å–∫–µ (–±–µ–∑ upload).

    –î–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—É—Ç—å –¥–æ–ª–∂–µ–Ω –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤–Ω—É—Ç—Ä–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏,
    –∑–∞–¥–∞–Ω–Ω–æ–π env `VIDEO_SERVICE_ALLOWED_INPUT_DIR`.
    """
    if ALLOWED_INPUT_DIR is None:
        raise HTTPException(
            403,
            "analyze-path is disabled. Set VIDEO_SERVICE_ALLOWED_INPUT_DIR to enable it.",
        )

    video_path = Path(request.path).expanduser().resolve()
    if not video_path.exists():
        raise HTTPException(404, f"Video not found: {video_path}")
    if not video_path.is_file():
        raise HTTPException(400, f"Path is not a file: {video_path}")
    if not _is_allowed_input_path(video_path):
        raise HTTPException(403, f"Path is outside allowed directory: {ALLOWED_INPUT_DIR}")

    allowed_extensions = {".mp4", ".mkv", ".avi", ".mov", ".webm"}
    ext = video_path.suffix.lower()
    if ext not in allowed_extensions:
        raise HTTPException(400, f"Unsupported format. Allowed: {allowed_extensions}")

    task_id = str(uuid.uuid4())
    settings = {
        "max_clips": max_clips,
        "min_duration": min_duration,
        "max_duration": max_duration,
        "enable_llm": enable_llm,
    }

    created_at = datetime.utcnow().isoformat()
    task_meta = {
        "task_id": task_id,
        "status": "pending",
        "progress": 0.0,
        "created_at": created_at,
        "video_path": str(video_path),
        "video_name": video_path.name,
        "settings": settings,
        "source": "path",
    }
    save_task_meta(task_id, task_meta)

    if USE_CELERY:
        from api.celery_app import analyze_video
        analyze_video.delay(str(video_path), settings, task_id)
    else:
        background_tasks.add_task(run_analysis_task, task_id, str(video_path), settings)

    return TaskStatus(
        task_id=task_id,
        status="pending",
        progress=0.0,
        created_at=created_at,
    )


@app.get("/tasks/{task_id}", response_model=TaskStatus, tags=["Analysis"])
async def get_task_status_endpoint(task_id: str):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞."""
    if USE_CELERY:
        from api.celery_app import get_task_status as get_celery_status
        status = get_celery_status(task_id)

        celery_to_api = {
            "PENDING": "pending",
            "STARTED": "processing",
            "PROCESSING": "processing",
            "SUCCESS": "completed",
            "FAILURE": "failed",
        }

        return TaskStatus(
            task_id=task_id,
            status=celery_to_api.get(status["status"], status["status"]),
            progress=status.get("progress", 0.0),
            result_url=f"/results/{task_id}" if status["status"] == "SUCCESS" else None,
            error=status.get("error"),
        )
    else:
        meta = get_task_meta(task_id)
        if not meta:
            raise HTTPException(404, "Task not found")

        return TaskStatus(
            task_id=task_id,
            status=meta.get("status", "unknown"),
            progress=meta.get("progress", 0.0),
            created_at=meta.get("created_at"),
            completed_at=meta.get("completed_at"),
            result_url=f"/results/{task_id}" if meta.get("status") == "completed" else None,
            error=meta.get("error"),
        )


@app.get("/results/{task_id}", response_model=AnalysisResultResponse, tags=["Results"])
async def get_analysis_result(task_id: str):
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
    meta = get_task_meta(task_id)
    if meta and meta.get("status") != "completed":
        raise HTTPException(400, f"Task not completed. Status: {meta.get('status')}")

    # –ß–∏—Ç–∞–µ–º public —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result_path = RESULTS_DIR / f"{task_id}.json"
    if not result_path.exists():
        raise HTTPException(404, "Result not found")

    try:
        with open(result_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception as e:
        raise HTTPException(500, f"Failed to read result: {e}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º public —á–∞—Å—Ç—å –µ—Å–ª–∏ –µ—Å—Ç—å
    public = data.get("public", data)

    viral_clips = []
    for i, c in enumerate(public.get("viral_clips", [])):
        viral_clips.append(ViralClipResponse(
            id=c.get("id", f"clip_{i}"),
            start=c.get("start", 0),
            end=c.get("end", 0),
            duration=c.get("duration", c.get("end", 0) - c.get("start", 0)),
            score=c.get("score", 0),
            score_breakdown=c.get("score_breakdown", {}),
            anchor_type=c.get("anchor_type", ""),
            reasons=c.get("reasons", []),
        ))

    chapters = []
    for i, ch in enumerate(public.get("chapters", [])):
        chapters.append(ChapterResponse(
            id=ch.get("id", f"chapter_{i}"),
            start=ch.get("start", 0),
            end=ch.get("end", 0),
            duration=ch.get("duration", ch.get("end", 0) - ch.get("start", 0)),
            title=ch.get("title", ""),
            description=ch.get("description", ""),
        ))

    summary_data = public.get("summary", {})
    summary = AnalysisSummaryResponse(
        total_scenes=summary_data.get("total_scenes", 0),
        total_speech_duration=summary_data.get("total_speech_duration", 0),
        speech_ratio=summary_data.get("speech_ratio", 0),
        mean_motion=summary_data.get("mean_motion", 0),
        mean_loudness=summary_data.get("mean_loudness", 0),
        mean_interest=summary_data.get("mean_interest", 0),
        detected_language=summary_data.get("detected_language"),
    )

    return AnalysisResultResponse(
        task_id=public.get("task_id", task_id),
        video_name=public.get("video_name", "video"),
        duration_seconds=public.get("duration_seconds", 0),
        processing_time_seconds=public.get("processing_time_seconds", 0),
        viral_clips=viral_clips,
        chapters=chapters,
        summary=summary,
        created_at=public.get("created_at"),
    )


@app.get("/results/{task_id}/full", tags=["Results"])
async def get_full_result(task_id: str):
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ (–≤–∫–ª—é—á–∞—è timeline –∏ —Ç.–¥.)."""
    full_path = RESULTS_DIR / f"{task_id}.full.json"
    if full_path.exists():
        return FileResponse(
            full_path,
            media_type="application/json",
            filename=f"analysis_full_{task_id}.json",
        )

    # Fallback –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
    result_path = RESULTS_DIR / f"{task_id}.json"
    if not result_path.exists():
        raise HTTPException(404, "Result not found")

    return FileResponse(
        result_path,
        media_type="application/json",
        filename=f"analysis_{task_id}.json",
    )


@app.get("/results/{task_id}/download", tags=["Results"])
async def download_result(task_id: str):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON."""
    result_path = RESULTS_DIR / f"{task_id}.json"
    if not result_path.exists():
        raise HTTPException(404, "Result file not found")

    return FileResponse(
        result_path,
        media_type="application/json",
        filename=f"analysis_{task_id}.json",
    )


@app.delete("/tasks/{task_id}", tags=["Analysis"])
async def delete_task(task_id: str):
    """–£–¥–∞–ª—è–µ—Ç –∑–∞–¥–∞—á—É –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã."""
    meta = get_task_meta(task_id)

    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    if meta:
        video_path = Path(meta.get("video_path", ""))
        if video_path.exists():
            video_path.unlink()

    # –£–¥–∞–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    for suffix in [".json", ".full.json"]:
        result_path = RESULTS_DIR / f"{task_id}{suffix}"
        if result_path.exists():
            result_path.unlink()

    # –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ Redis
    client = get_redis_client()
    if client:
        client.delete(f"task_meta:{task_id}")

    return {"message": "Task deleted"}


@app.get("/tasks", response_model=List[TaskStatus], tags=["Analysis"])
async def list_tasks(limit: int = Query(10, ge=1, le=100), status: Optional[str] = None):
    """–°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á."""
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏ –∑–∞–¥–∞—á –∏–∑ Redis
    client = get_redis_client()
    if not client:
        return []

    keys = client.keys("task_meta:*")
    tasks = []

    for key in keys[:limit * 2]:  # –ë–µ—Ä—ë–º —Å –∑–∞–ø–∞—Å–æ–º –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        data = client.get(key)
        if data:
            meta = json.loads(data)
            if status and meta.get("status") != status:
                continue
            tasks.append(TaskStatus(
                task_id=meta.get("task_id", ""),
                status=meta.get("status", "unknown"),
                progress=meta.get("progress", 0.0),
                created_at=meta.get("created_at"),
                completed_at=meta.get("completed_at"),
                result_url=f"/results/{meta.get('task_id')}" if meta.get("status") == "completed" else None,
                error=meta.get("error"),
            ))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    tasks.sort(key=lambda x: x.created_at or "", reverse=True)

    return tasks[:limit]


# ============================================================================
# Background Task (non-Celery mode)
# ============================================================================

def run_analysis_task(task_id: str, video_path: str, settings: Dict[str, Any]) -> None:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –≤ —Ñ–æ–Ω–µ (–±–µ–∑ Celery)."""
    import sys
    import time
    from pathlib import Path

    project_root = Path(__file__).parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

    try:
        update_task_progress(task_id, 0.1, "processing")

        from config.settings import VideoServiceSettings
        from core.dag_executor import DAGExecutor, DAGNode
        from models.serde import to_jsonable

        # –°–æ–∑–¥–∞—ë–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        video_settings = VideoServiceSettings(
            max_viral_clips=settings.get("max_clips", 8),
            min_clip_duration=settings.get("min_duration", 30.0),
            max_clip_duration=settings.get("max_duration", 60.0),
            llm_enabled=settings.get("enable_llm", False),
            block_analysis_enabled=settings.get("enable_llm", False),
            enable_llm_refine=settings.get("enable_llm", False),
            llm_base_url=os.environ.get("VIDEO_SERVICE_LLM_BASE_URL", "http://host.docker.internal:11434"),
            llm_model=os.environ.get("VIDEO_SERVICE_LLM_MODEL", "qwen2.5-coder:14b"),
        )

        update_task_progress(task_id, 0.2, "processing", "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω (—Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –ø–æ –Ω–æ–¥–∞–º)
        from main import run_dag_pipeline

        context = {"input_path": video_path, "settings": video_settings, "task_id": task_id}

        start_time = time.monotonic()
        def on_progress(p: float, msg: str) -> None:
            update_task_progress(task_id, p, "processing", msg)

        result_context, exec_result = run_dag_pipeline(context, video_settings, progress_callback=on_progress)
        processing_time = time.monotonic() - start_time

        update_task_progress(task_id, 0.95, "processing", "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result = to_jsonable(result_context)
        result["processing_time_seconds"] = processing_time
        result["task_id"] = task_id

        # Public result
        public_path = RESULTS_DIR / f"{task_id}.json"
        with open(public_path, "w", encoding="utf-8") as f:
            json.dump(result.get("public", result), f, indent=2, ensure_ascii=False)

        # Full result
        full_path = RESULTS_DIR / f"{task_id}.full.json"
        with open(full_path, "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        meta = get_task_meta(task_id) or {}
        meta["status"] = "completed"
        meta["progress"] = 1.0
        meta["completed_at"] = datetime.utcnow().isoformat()
        save_task_meta(task_id, meta)
        _publish_task_event(
            task_id,
            {
                "task_id": task_id,
                "status": "completed",
                "progress": 1.0,
                "message": "–ì–æ—Ç–æ–≤–æ",
            },
        )

    except Exception as e:
        meta = get_task_meta(task_id) or {}
        meta["status"] = "failed"
        meta["error"] = str(e)
        meta["completed_at"] = datetime.utcnow().isoformat()
        save_task_meta(task_id, meta)
        _publish_task_event(
            task_id,
            {
                "task_id": task_id,
                "status": "failed",
                "progress": meta.get("progress", 0.0),
                "error": str(e),
                "message": "–û—à–∏–±–∫–∞",
            },
        )
        print(f"Task {task_id} failed: {e}")

    finally:
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        _cleanup_input_if_temp(video_path)


# ============================================================================
# Startup/Shutdown Events
# ============================================================================

@app.on_event("startup")
async def startup_event():
    """–î–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ."""
    print("üöÄ Video Analyzer API started")
    print(f"   Version: 2.0.0")
    print(f"   Temp dir: {TEMP_DIR}")
    print(f"   Results dir: {RESULTS_DIR}")
    print(f"   Celery: {'enabled' if USE_CELERY else 'disabled'}")


@app.on_event("shutdown")
async def shutdown_event():
    """–î–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ."""
    print("üëã Video Analyzer API shutting down")
